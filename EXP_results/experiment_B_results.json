{
  "experiment_id": "B_wav2vec2_conformer_ctc",
  "model_configuration": {
    "architecture": "wav2vec2-base + 4-layer Conformer + CTC",
    "parameters": {
      "wav2vec2_layers": 12,
      "conformer_layers": 4,
      "conformer_dim": 512,
      "conformer_heads": 8,
      "conv_kernel_size": 31,
      "total_params": "124M",
      "trainable_params": "124M",
      "added_params_vs_baseline": "29M"
    }
  },
  "training_details": {
    "total_epochs": 100,
    "total_training_time_hours": 280.0,
    "avg_epoch_time_minutes": 168,
    "hardware": "4x RTX 5090 32GB",
    "batch_size": 32,
    "effective_batch_size": 128,
    "optimizer": "AdamW",
    "learning_rate_schedule": "linear_warmup_polynomial_decay"
  },
  "final_results": {
    "validation": {
      "wer": 3.0,
      "cer": 1.4,
      "loss": 0.159
    },
    "test_sets": {
      "librispeech_test_clean": {
        "wer": 2.7,
        "cer": 1.3,
        "rtf": 0.044,
        "first_token_latency_ms": 128
      },
      "librispeech_test_other": {
        "wer": 4.5,
        "cer": 2.2,
        "rtf": 0.045,
        "first_token_latency_ms": 131
      },
      "cv_en_test": {
        "wer": 4.0,
        "cer": 2.0,
        "rtf": 0.044,
        "first_token_latency_ms": 129
      },
      "tedlium_test": {
        "wer": 4.1,
        "cer": 2.0,
        "rtf": 0.045,
        "first_token_latency_ms": 130
      }
    },
    "average_metrics": {
      "avg_test_wer": 3.83,
      "avg_test_cer": 1.88,
      "avg_rtf": 0.0445,
      "avg_latency_ms": 129.5
    }
  },
  "improvements_over_baseline": {
    "val_wer_reduction": "11.8%",
    "test_clean_wer_reduction": "12.9%",
    "test_other_wer_reduction": "13.5%",
    "avg_test_wer_reduction": "13.0%",
    "rtf_increase": "11.3%"
  },
  "inference_performance": {
    "batch_inference": {
      "batch_size": 32,
      "throughput_hours_per_hour": 22.5,
      "gpu_memory_usage_gb": 10.8
    },
    "streaming_inference": {
      "chunk_size_ms": 2000,
      "lookahead_ms": 500,
      "latency_ms": 129.5,
      "rtf": 0.0445
    }
  },
  "conformer_analysis": {
    "attention_pattern": "local_global_hybrid",
    "conv_receptive_field_ms": 620,
    "position_encoding": "relative",
    "layer_contributions": {
      "layer_1": "23.4%",
      "layer_2": "28.7%",
      "layer_3": "26.1%",
      "layer_4": "21.8%"
    }
  },
  "error_analysis": {
    "most_confused_words": [
      {"pair": ["the", "a"], "count": 367},
      {"pair": ["and", "in"], "count": 298},
      {"pair": ["to", "two"], "count": 176}
    ],
    "error_by_type": {
      "substitution": "57.2%",
      "deletion": "25.8%",
      "insertion": "17.0%"
    },
    "challenging_conditions": {
      "fast_speech_wer": 5.2,
      "accented_speech_wer": 5.9,
      "noisy_speech_wer": 7.3
    }
  },
  "ablation_component": "conformer_encoder",
  "notes": "Addition of 4-layer Conformer encoder provides modest improvements (13% WER reduction) with minimal RTF impact (+11.3%)."
}